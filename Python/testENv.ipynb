{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "from os import path\n",
    "from sklearn.feature_extraction import image\n",
    "import imageio\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "def convertCSVtoNP(Filepath):\n",
    "    supportedFileFormats = [\"png\",\"jpeg\",\"jpg\",\"bmp\"]\n",
    "\n",
    "    if not path.isfile(Filepath):\n",
    "        raise ValueError(\"Path: '{}' is no file!\".format(Filepath))\n",
    "\n",
    "    if not path.splitext(Filepath)[1] in [\".txt\",\".csv\"]:\n",
    "        raise ValueError(\"Selected fileformat {} is not valid. Only .csv or .txt are allowed!\".format(path.splitext(Filepath)[1]))\n",
    "\n",
    "    with open(Filepath, \"r\") as f:\n",
    "        #read all the lines from the file \n",
    "        lines = f.readlines()\n",
    "\n",
    "        #first line only has comments, we ignore it \n",
    "\n",
    "        #second line has the image dimensions so we need to read it as integer \n",
    "        try: \n",
    "            dataWidth = int(lines[1])\n",
    "            x,y = [(int(x)) for x in lines[2].split()]\n",
    "        except ValueError:\n",
    "            raise ValueError(\"Error reading the image dimensions. Check that there are two integers seperated by whitespace!\")\n",
    "\n",
    "        #create an empty numpy array to store the image data.\n",
    "        outputArray = np.zeros((x,y,dataWidth))\n",
    "\n",
    "        #drop the first two rows of data\n",
    "        lines = lines[3:]\n",
    "\n",
    "        for index, line in enumerate(lines):\n",
    "            #each line contains the r,g,b information separated by blank spaces  \n",
    "            try:\n",
    "                inputValues = [(int(x)) for x in line.split()]\n",
    "            except ValueError:\n",
    "                raise ValueError(\"Error in line {}. Check that there are three integers seperated by whitespace!\".format(index+2))\n",
    "\n",
    "            outputArray[math.floor(index / y),index % y] = np.array(inputValues)\n",
    "\n",
    "    return outputArray\n",
    "\n",
    "def loadNetworkModel(Path, MaxValue = 2.0):\n",
    "    #as we are using an advanced activation function in the original file we have to create it here as well. Otherwise Tensorflow does \n",
    "    #not know what function is refferenced \n",
    "    def create_relu_advanced(max_value=2.0):        \n",
    "            def relu_advanced(x):\n",
    "                return K.relu(x, max_value=K.cast_to_floatx(max_value))\n",
    "            return relu_advanced\n",
    "\n",
    "    #create a special softmax function so that we limit the output before applying softmax to -1...1\n",
    "    #usefull for the calculation inside the neural network with fixedpoint. Otherwise we might oversaturate the output \n",
    "    def tanh_softmax(x):\n",
    "        return K.softmax(K.tanh(x))          \n",
    "        \n",
    "    #as we want the second model to feed into the next model we need to change the activation function of the last layer\n",
    "    model = keras.models.load_model(Path,custom_objects={'relu_advanced':create_relu_advanced(MaxValue),'tanh_softmax':tanh_softmax})\n",
    "\n",
    "    return model\n",
    "\n",
    "colors = np.array([(0,0,0),(0,255,0),(0,0,255),(255,255,0),(255,0,0),(0,255,255),(0,0,0),(255,255,255)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simOutput = convertCSVtoNP(r\"C:\\Users\\Unknown\\Documents\\Master-Convolution\\VHDL\\Code\\Testbench\\out1.txt\")\n",
    "#simOutput = simOutput.astype(float) / 2**5\n",
    "\n",
    "firstModel = loadNetworkModel(r\"C:\\Users\\Unknown\\Documents\\Master-Convolution\\Python\\first.h5\")\n",
    "secondModel  = loadNetworkModel(r\"C:\\Users\\Unknown\\Documents\\Master-Convolution\\Python\\second.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "originalImage = imageio.imread(r\"C:\\Users\\Unknown\\Documents\\Master-Convolution\\Python\\Subshapes\\input.jpg\")\n",
    "firstNetworkInput = image.extract_patches_2d(originalImage[:,:,0],(7,7))\n",
    "\n",
    "firstNetworkInput -= np.min(firstNetworkInput)\n",
    "firstNetworkInput = firstNetworkInput.astype(float) / np.max(firstNetworkInput).astype(float)\n",
    "\n",
    "firstModelOutput = firstModel.predict(firstNetworkInput, batch_size=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "firstModelOutput = np.reshape(firstModelOutput,(originalImage.shape[0]-6,-1,7))\n",
    "#simOutput = simOutput[:firstModelOutput.shape[0],:firstModelOutput.shape[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#secondStageInputSim = image.extract_patches_2d(simOutput,(21,21))\n",
    "\n",
    "secondStageInputPy  = image.extract_patches_2d(firstModelOutput,(21,21))\n",
    "#secondStageInputSim = secondStageInputSim[:,::7,::7].copy()\n",
    "secondStageInputPy  = secondStageInputPy[:,::7,::7].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "bigInput = image.extract_patches_2d(originalImage[:,:,0],(21,21))\n",
    "bigInput -= np.min(bigInput)\n",
    "bigInput = bigInput.astype(float) / np.max(bigInput).astype(float)\n",
    "\n",
    "secondStageInputTraining = np.zeros((len(bigInput),7,3,3))\n",
    "\n",
    "#in order to predict the output of the first network we need an array with the shape of (-1,firstInputShape[1],firstInputShape[2])\n",
    "#so we need to subset the input. \n",
    "for j in range(3):\n",
    "    for k in range(3):\n",
    "        #create the subset from the patches  \n",
    "        subSlice = bigInput[:,j* 7: (j+1)*7, k * 7: (k+1)*7]\n",
    "        #apply the network to the patches\n",
    "        secondStageInputTraining[:,:,j,k] = firstModel.predict(subSlice ,batch_size=65536)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#secondStageInputSim = np.transpose(secondStageInputSim, (0,3,1,2))\n",
    "secondStageInputPy  = np.transpose(secondStageInputPy, (0,3,1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#secondStageOutputSim        = secondModel.predict(secondStageInputSim,batch_size=2048)\n",
    "secondStageOutputPy         = secondModel.predict(secondStageInputPy,batch_size=2048)\n",
    "secondStageOutputTraining   = secondModel.predict(secondStageInputTraining,batch_size=2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#secondStageOutputSim        = np.reshape(secondStageOutputSim, (firstModelOutput.shape[0]-20,-1,6))\n",
    "secondStageOutputPy         = np.reshape(secondStageOutputPy, (firstModelOutput.shape[0]-20,-1,6))  \n",
    "secondStageOutputTraining   = np.reshape(secondStageOutputTraining, (originalImage.shape[0]-20,-1,6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = np.array([(0,0,0),(0,255,0),(0,0,255),(255,255,0),(255,0,0),(0,0,0),(0,0,0),(255,255,255)])\n",
    "\n",
    "#imageSim        = colors[np.argmax(secondStageOutputSim,axis=2)]\n",
    "imagePy         = colors[np.argmax(secondStageOutputPy,axis=2)]\n",
    "imageTraining   = colors[np.argmax(secondStageOutputTraining,axis=2)]\n",
    "imageFirstNetwork    = colors[np.argmax(firstModelOutput,axis=2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from int32 to uint8. Range [0, 255]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from int32 to uint8. Range [0, 255]. Convert image to uint8 prior to saving to suppress this warning.\n",
      "Lossy conversion from int32 to uint8. Range [0, 255]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    }
   ],
   "source": [
    "#imageio.imwrite(\"Sim.jpg\",imageSim)\n",
    "imageio.imwrite(\"Py.jpg\",imagePy)\n",
    "imageio.imwrite(\"Training.jpg\",imageTraining)\n",
    "imageio.imwrite(\"First Output.jpg\", imageFirstNetwork)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9999990463257404\n",
      "0.1609769080103107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from float64 to uint8. Range [0.0, 255.0]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    }
   ],
   "source": [
    "#dif = simOutput-firstModelOutput\n",
    "# dif = dif**2\n",
    "\n",
    "# print(np.max(dif))\n",
    "# print(np.std(dif))\n",
    "\n",
    "# difSum = np.sum(dif,axis=2)\n",
    "\n",
    "# difSum -= np.min(difSum)\n",
    "# difSum = difSum/np.max(difSum)\n",
    "\n",
    "# difPic = np.round(difSum * 255)\n",
    "# imageio.imwrite(\"Dif.jpg\",difPic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simSecondLayerInput = convertCSVtoNP(r\"C:\\Users\\Unknown\\Documents\\Master-Convolution\\VHDL\\Code\\Testbench\\out3.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-32. -32. -32. -32. -32. -32.  32. -32. -32. -32. -32. -32. -32.  32.\n",
      " -32. -32. -32. -32. -32. -32.  32. -32. -32. -32. -32. -32. -32.  32.\n",
      " -32. -32. -32. -32. -32. -32.  32. -32. -32. -32. -32. -32. -32.  32.\n",
      " -32. -32. -32. -32. -32. -32.  32. -32. -32. -32. -32. -32. -32.  32.\n",
      " -32. -32. -32. -32. -32. -32.  32.]\n",
      "[[[-1. -1. -1.]\n",
      "  [-1. -1. -1.]\n",
      "  [-1. -1. -1.]]\n",
      "\n",
      " [[-1. -1. -1.]\n",
      "  [-1. -1. -1.]\n",
      "  [-1. -1. -1.]]\n",
      "\n",
      " [[-1. -1. -1.]\n",
      "  [-1. -1. -1.]\n",
      "  [-1. -1. -1.]]\n",
      "\n",
      " [[-1. -1. -1.]\n",
      "  [-1. -1. -1.]\n",
      "  [-1. -1. -1.]]\n",
      "\n",
      " [[-1. -1. -1.]\n",
      "  [-1. -1. -1.]\n",
      "  [-1. -1. -1.]]\n",
      "\n",
      " [[-1. -1. -1.]\n",
      "  [-1. -1. -1.]\n",
      "  [-1. -1. -1.]]\n",
      "\n",
      " [[ 1.  1.  1.]\n",
      "  [ 1.  1.  1.]\n",
      "  [ 1.  1.  1.]]]\n"
     ]
    }
   ],
   "source": [
    "# print(simSecondLayerInput[125,712])\n",
    "\n",
    "# simSecondLayerInput = np.reshape(simSecondLayerInput,(-1, simSecondLayerInput.shape[-1]))\n",
    "# simSecondLayerInput = np.reshape(simSecondLayerInput,(-1,3,3,7))\n",
    "# simSecondLayerInput = np.transpose(simSecondLayerInput,(0,3,1,2))\n",
    "\n",
    "# simSecondLayerInput = simSecondLayerInput.astype(float) / 2**5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#simFinalOut = secondModel.predict(simSecondLayerInput, batch_size = 8096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from int32 to uint8. Range [0, 255]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    }
   ],
   "source": [
    "# secondStageOutputSim    = np.reshape(simFinalOut, (720,1280,6))\n",
    "# imageSim                = colors[np.argmax(secondStageOutputSim,axis=2)]\n",
    "# imageio.imwrite(\"SimTotal.jpg\",imageSim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lossy conversion from int32 to uint8. Range [0, 255]. Convert image to uint8 prior to saving to suppress this warning.\n"
     ]
    }
   ],
   "source": [
    "bigInput = image.extract_patches_2d(originalImage[:,:,0],(21,21))\n",
    "bigInput -= np.min(bigInput)\n",
    "bigInput = bigInput.astype(float) / np.max(bigInput).astype(float)\n",
    "\n",
    "secondStageInputTraining = np.zeros((len(bigInput),7,3,3))\n",
    "\n",
    "#in order to predict the output of the first network we need an array with the shape of (-1,firstInputShape[1],firstInputShape[2])\n",
    "#so we need to subset the input. \n",
    "for j in range(3):\n",
    "    for k in range(3):\n",
    "        missmatch = 7\n",
    "        #create the subset from the patches  \n",
    "        subSlice = bigInput[:,j* missmatch: (j*missmatch)+7, k * missmatch: (k*missmatch)+7]\n",
    "        #apply the network to the patches\n",
    "        secondStageInputTraining[:,:,j,k] = firstModel.predict(subSlice ,batch_size=65536)\n",
    "\n",
    "secondStageOutputTraining   = secondModel.predict(secondStageInputTraining,batch_size=2048)\n",
    "secondStageOutputTraining   = np.reshape(secondStageOutputTraining, (originalImage.shape[0]-20,-1,6))\n",
    "imageTraining   = colors[np.argmax(secondStageOutputTraining,axis=2)]\n",
    "imageio.imwrite(\"Training first.jpg\",imageTraining)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(r\"C:\\Users\\Unknown\\Documents\\Master-Convolution\\VHDL\\Code\\Testbench\\in3.txt\",\"w\") as f:\n",
    "#     f.write(\"First Layer Sim Out\\n\")\n",
    "#     f.write(\"{} {}\\n\".format(secondStageOutputTraining.shape[0],secondStageOutputTraining.shape[1]))\n",
    "\n",
    "#     for val in secondStageInputTraining:\n",
    "#         for i in range(3*3*7):\n",
    "#             f.write(\"{} \".format(int(np.transpose(val,(1,2,0)).flatten()[i]*2**5)))\n",
    "#         f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "09e3b494da6579ad0894adc07fe75ba275c100a5baf9cbf33c77973783e94f86"
  },
  "kernelspec": {
   "display_name": "Python 3.8.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
